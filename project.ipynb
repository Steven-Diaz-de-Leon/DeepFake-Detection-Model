{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyqZe_csh6Ez"
   },
   "source": [
    "### List modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3eei2McYh6E4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import warnings\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITgyTpKRh6FC"
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avXnBYQZh6FE",
    "outputId": "d52aac8d-87ca-4a37-fe17-c7123e65ac38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples:  401\n",
      "Test samples:  400\n"
     ]
    }
   ],
   "source": [
    "with open(\"variables/train_size\", 'rb') as f:\n",
    "    train_size = pickle.load(f)\n",
    "with open(\"variables/test_size\", 'rb') as f:\n",
    "    test_size = pickle.load(f)  \n",
    "print(\"Train samples: \", train_size)\n",
    "print(\"Test samples: \", test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a8mhMB0h6FI"
   },
   "source": [
    "### File extensions and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKFfrYQih6FK",
    "outputId": "10e77c52-bc8e-403b-ed89-6800becbffdc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions:  ['mp4', 'json']\n",
      "Files with extension  mp4 :  400\n",
      "Files with extension  json :  1\n"
     ]
    }
   ],
   "source": [
    "with open(\"variables/train_list\", 'rb') as f:\n",
    "    train_list = pickle.load(f)\n",
    "with open(\"variables/ext_dict\", 'rb') as f:\n",
    "    ext_dict = pickle.load(f)\n",
    " \n",
    "print(\"Extensions: \", ext_dict)      \n",
    "\n",
    "\n",
    "for file_ext in ext_dict:\n",
    "    print(\"Files with extension \",file_ext, \": \", len([file for file in train_list if  file.endswith(file_ext)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking json file\n",
    "<img src=\"files/labels.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uViuK-j8h6FR"
   },
   "source": [
    "#### ^^ All missing data has in original is associated with the label REAL (Real videos are the originals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "dUjVCiHIh6FW",
    "outputId": "c8a67d84-19ba-4905-f389-08012c13be53"
   },
   "source": [
    "# Plot data distribution\n",
    "<img src=\"files/plot data.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in /home/deathwish/anaconda3/lib/python3.8/site-packages (2.5.2)\n",
      "Requirement already satisfied: numpy in /home/deathwish/.local/lib/python3.8/site-packages (from facenet-pytorch) (1.19.5)\n",
      "Requirement already satisfied: torchvision in /home/deathwish/.local/lib/python3.8/site-packages (from facenet-pytorch) (0.9.1)\n",
      "Requirement already satisfied: requests in /home/deathwish/anaconda3/lib/python3.8/site-packages (from facenet-pytorch) (2.24.0)\n",
      "Requirement already satisfied: pillow in /home/deathwish/anaconda3/lib/python3.8/site-packages (from facenet-pytorch) (7.2.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/deathwish/anaconda3/lib/python3.8/site-packages (from requests->facenet-pytorch) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/deathwish/anaconda3/lib/python3.8/site-packages (from requests->facenet-pytorch) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/deathwish/anaconda3/lib/python3.8/site-packages (from requests->facenet-pytorch) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/deathwish/anaconda3/lib/python3.8/site-packages (from requests->facenet-pytorch) (2.10)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/deathwish/.local/lib/python3.8/site-packages (from torchvision->facenet-pytorch) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /home/deathwish/.local/lib/python3.8/site-packages (from torch==1.8.1->torchvision->facenet-pytorch) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lwkbRCxRh6FZ"
   },
   "outputs": [],
   "source": [
    "class DetectionPipeline:\n",
    "\n",
    "    def __init__(self, detector, n_frames=None, batch_size=60, resize=None):\n",
    "\n",
    "        self.detector = detector\n",
    "        self.n_frames = n_frames\n",
    "        self.batch_size = batch_size\n",
    "        self.resize = resize\n",
    "        \n",
    "            \n",
    "    def __call__(self, filename):\n",
    " \n",
    "   \n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(v_len)\n",
    "    \n",
    "        if self.n_frames is None:\n",
    "            sample = np.arange(0, v_len)\n",
    "        else:\n",
    "            sample = np.linspace(0, v_len - 1, self.n_frames).astype(int)\n",
    "\n",
    "   \n",
    "        faces = []\n",
    "        frames = []\n",
    "        for j in range(v_len):\n",
    "            success = v_cap.grab()\n",
    "            if j in sample:\n",
    "    \n",
    "                success, frame = v_cap.retrieve()\n",
    "                if not success:\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "                \n",
    "    \n",
    "                if self.resize is not None:\n",
    "                    frame = frame.resize([int(d * self.resize) for d in frame.size])\n",
    "                frames.append(frame)\n",
    "\n",
    "   \n",
    "                if len(frames) % self.batch_size == 0 or j == sample[-1]:\n",
    "                    faces.extend(self.detector(frames))\n",
    "                    frames = []\n",
    "\n",
    "        v_cap.release()\n",
    "        \n",
    "        return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VWSeYD_zh6Fb"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def process_faces(faces, resnet):\n",
    "\n",
    "    faces = [f for f in faces if f is not None]\n",
    "    if(len(faces) == 0):\n",
    "        return []\n",
    "\n",
    "    faces = torch.cat(faces).to(device)\n",
    "    if(len(faces)<290):\n",
    "        return []\n",
    "\n",
    "    faces = faces[:290]\n",
    "\n",
    "    embeddings = resnet(faces)\n",
    "\n",
    "    centroid = embeddings.mean(dim=0)\n",
    "    \n",
    "    x = (embeddings - centroid).norm(dim=1).cpu().numpy()\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d4b273b2d2d74072822ac3e0064a0821",
      "faa5b7c4d5ed41ee80786a655f7a7cf4",
      "176a392c6fc546a2b4b6572841a94c51",
      "096be3a30731447a9b9beb6a4231b8ce",
      "0168ae0b55444dc4a6e2fc2425694f0e",
      "56358e13ff8045169c99bb6fa487581f",
      "247433fe7c0a425eacc797220e1ce9d0",
      "2276332008274596b7d4c63135036da2"
     ]
    },
    "id": "Stxung1Th6Fc",
    "outputId": "0405e20a-644e-4c80-8f92-8974b9a9d9f3"
   },
   "outputs": [],
   "source": [
    "#Code for extracting and processing faces from videos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#detection_pipeline = DetectionPipeline(detector=mtcnn, batch_size=60, resize=0.25)\n",
    "#import json\n",
    "\n",
    "#with open('/content/drive/Shared drives/deepfake/deepfake-detection-challenge/train_sample_videos/metadata.json') as f:\n",
    "#  data = json.load(f)\n",
    "\n",
    "#filenames = glob.glob('/content/drive/Shared drives/deepfake/deepfake-detection-challenge/train_sample_videos/*.mp4')\n",
    "#total_files = len(filenames)\n",
    "\n",
    "#X = []\n",
    "#y = []\n",
    "#start = time.time()\n",
    "#n_processed = 0\n",
    "\n",
    "#with torch.no_grad():\n",
    "#  for i, filename in tqdm(enumerate(filenames), total=len(filenames)):\n",
    "#    print(i, filename)\n",
    "#    faces = detection_pipeline(filename)\n",
    "#    z = process_faces(faces, resnet)\n",
    "#    if len(z)!=0:\n",
    "#      X.append(z)\n",
    "#      if data[filename[87:]]['label'] == 'FAKE':\n",
    "#        y.append(1)\n",
    "#      else:\n",
    "#        y.append(0)\n",
    "#    n_processed += len(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofUjhaQyiWt1",
    "outputId": "ee30a005-48b1-4eab-8f69-df8e73840e4c"
   },
   "outputs": [],
   "source": [
    "with open(\"variables/casiaX\", 'rb') as f:\n",
    "    casiaX = pickle.load(f)\n",
    "with open(\"variables/casiaY\", 'rb') as f:\n",
    "    casiaY = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/deathwish/anaconda3/lib/python3.8/site-packages (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deathwish/.local/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deathwish/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/deathwish/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/deathwish/.local/lib/python3.8/site-packages (from scikit-learn) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "u-uoydiM7f3J"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(casiaX, casiaY, test_size=0.85, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CASIA-Webface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2EKJr0sM7i0B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression:  0.8012820512820513\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred_lr = clf.predict(X_test)\n",
    "print(\"Logisitic Regression: \", accuracy_score(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2ulyJO5e7pib"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_gnb = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"GaussianNB:\", accuracy_score(y_test,y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "mm1F_ZQT7umU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:  0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_svm = clf.predict(X_test)\n",
    "print(\"SVM: \",accuracy_score(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKRr8keaDGcs",
    "outputId": "3638ec5a-c642-42d0-9b70-e33d747210ae"
   },
   "outputs": [],
   "source": [
    "#using VGGFace2\n",
    "with open(\"variables/VGGX\", 'rb') as f:\n",
    "    X1 = pickle.load(f)\n",
    "with open(\"variables/VGGY\", 'rb') as f:\n",
    "    y1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xp45B2fXDJNK",
    "outputId": "c7e6ed24-def9-4400-cebd-c267aa7f6ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression:  0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.85, random_state=5)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred_lr = clf.predict(X_test)\n",
    "print(\"Logisitic Regression: \", accuracy_score(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pm5PPLNcDOIM",
    "outputId": "93ed052c-eac4-4e5c-dd31-32ba6a83c325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: 0.6826923076923077\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_gnb = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"GaussianNB:\", accuracy_score(y_test,y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjGDJL5KDL6D",
    "outputId": "73c243f4-fb12-42ce-8167-02dac799b185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:  0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_svm = clf.predict(X_test)\n",
    "print(\"SVM: \",accuracy_score(y_test,y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepfake.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0168ae0b55444dc4a6e2fc2425694f0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "096be3a30731447a9b9beb6a4231b8ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2276332008274596b7d4c63135036da2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_247433fe7c0a425eacc797220e1ce9d0",
      "value": " 400/400 [1:19:03&lt;00:00, 11.86s/it]"
     }
    },
    "176a392c6fc546a2b4b6572841a94c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56358e13ff8045169c99bb6fa487581f",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0168ae0b55444dc4a6e2fc2425694f0e",
      "value": 400
     }
    },
    "2276332008274596b7d4c63135036da2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "247433fe7c0a425eacc797220e1ce9d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56358e13ff8045169c99bb6fa487581f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4b273b2d2d74072822ac3e0064a0821": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_176a392c6fc546a2b4b6572841a94c51",
       "IPY_MODEL_096be3a30731447a9b9beb6a4231b8ce"
      ],
      "layout": "IPY_MODEL_faa5b7c4d5ed41ee80786a655f7a7cf4"
     }
    },
    "faa5b7c4d5ed41ee80786a655f7a7cf4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
